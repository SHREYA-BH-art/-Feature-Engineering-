{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment Questions**"
      ],
      "metadata": {
        "id": "SHxbiMbq6zX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "*  A **parameter** in machine learning refers to a variable that the model **learns from the training data**. These values define how the model makes predictions. For example, in linear regression, the slope and intercept are parameters adjusted during training to minimize error. Parameters differ from **hyperparameters**, which are set before training and control the learning process (e.g., learning rate or tree depth). Accurate parameter values are essential for the model's performance, as they determine how well the model captures patterns in the data."
      ],
      "metadata": {
        "id": "CIZeiVMB6_kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is correlation?\n",
        "What does negative correlation mean?\n",
        "* **Correlation** is a statistical measure that describes the strength and direction of a relationship between two variables. It ranges from -1 to 1. A **positive correlation** means that as one variable increases, the other also increases. A **negative correlation** means that as one variable increases, the other decreases — they move in opposite directions. For example, if time spent exercising increases and body weight decreases, they have a negative correlation. A correlation close to 0 indicates no linear relationship between variables."
      ],
      "metadata": {
        "id": "Sa0nsCso7UQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "* **Machine Learning** is a branch of artificial intelligence that enables systems to learn from data and improve their performance without being explicitly programmed. It focuses on building models that can recognize patterns, make predictions, or take actions based on input data.\n",
        "\n",
        "The main components of Machine Learning are:\n",
        "\n",
        "1. **Data** – The foundation used to train and evaluate models.\n",
        "2. **Model** – An algorithm that learns patterns from the data.\n",
        "3. **Features** – Input variables used to make predictions.\n",
        "4. **Training** – The process of teaching the model using data.\n",
        "5. **Evaluation** – Measuring model performance."
      ],
      "metadata": {
        "id": "qd7jihEz7kdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does loss value help in determining whether the model is good or not?\n",
        "* The **loss value** measures how well a machine learning model’s predictions match the actual outcomes. It quantifies the error between predicted and true values. A **lower loss** indicates that the model is making accurate predictions, while a **higher loss** suggests poor performance. During training, the model adjusts its parameters to minimize the loss, improving its accuracy. Monitoring the loss value over time helps assess whether the model is learning or overfitting. It’s a key metric in determining model quality and guiding improvements.\n"
      ],
      "metadata": {
        "id": "Xpagn0ag7y10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What are continuous and categorical variables?\n",
        "* Continuous variables are numerical values that can take any value within a range. They are measurable and can be divided infinitely. Examples include height, temperature, and age — values like 5.6 or 72.3 are possible.\n",
        "\n",
        "Categorical variables, on the other hand, represent distinct groups or categories. They are not measured numerically but represent types or labels. Examples include gender, color, or country. Categorical variables can be nominal (no order, like color) or ordinal (ordered, like education level).\n",
        "\n",
        "Understanding both types is essential for proper data preprocessing and model selection."
      ],
      "metadata": {
        "id": "yj-MnqT-8BYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "* Handling categorical variables in Machine Learning involves converting them into a numerical format that algorithms can process. Common techniques include:\n",
        "\n",
        "Label Encoding – Assigns a unique integer to each category. Best for ordinal data where order matters.\n",
        "\n",
        "One-Hot Encoding – Creates binary columns for each category. Suitable for nominal (unordered) data.\n",
        "\n",
        "Target Encoding – Replaces categories with the mean of the target variable for that category.\n",
        "\n",
        "Frequency Encoding – Replaces each category with its frequency in the dataset.\n",
        "\n",
        "Choosing the right method depends on the data and the model being used."
      ],
      "metadata": {
        "id": "gO78bl558NIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What do you mean by training and testing a dataset?\n",
        "* Training and testing a dataset refers to splitting data into two parts to build and evaluate a machine learning model:\n",
        "\n",
        "Training dataset: This portion is used to train the model. The algorithm learns patterns, relationships, and parameters from this data to make accurate predictions.\n",
        "\n",
        "Testing dataset: This separate portion is used to evaluate how well the trained model performs on unseen data. It checks the model’s generalization ability and helps detect overfitting.\n",
        "\n",
        "This split ensures that the model not only memorizes data but also performs well in real-world scenarios."
      ],
      "metadata": {
        "id": "_LRfOZia8Ydm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is sklearn.preprocessing?\n",
        "* sklearn.preprocessing is a module in Scikit-learn, a popular Python library for machine learning. It provides a set of tools for preprocessing data, which is a crucial step before training models. This module includes functions and classes to:\n",
        "\n",
        "Scale features (e.g., StandardScaler, MinMaxScaler)\n",
        "\n",
        "Encode categorical variables (e.g., OneHotEncoder, LabelEncoder)\n",
        "\n",
        "Normalize data\n",
        "\n",
        "Generate polynomial features (PolynomialFeatures)\n",
        "\n",
        "Impute missing values (SimpleImputer)\n",
        "\n",
        "Using sklearn.preprocessing ensures that your data is in the right format and scale for machine learning algorithms to perform effectively."
      ],
      "metadata": {
        "id": "rgdH_4Uw8fem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is a Test set?\n",
        "* A test set is a portion of a dataset that is not used during model training but is reserved to evaluate the model's performance on unseen data. It helps determine how well the trained model generalizes to new, real-world inputs.\n",
        "\n",
        "The test set is critical because:\n",
        "\n",
        "It provides an unbiased assessment of a model’s accuracy.\n",
        "\n",
        "It helps detect overfitting (when the model performs well on training data but poorly on new data).\n",
        "\n",
        "It’s used for final performance reporting (e.g., accuracy, precision, recall)."
      ],
      "metadata": {
        "id": "MaIhQjbo8mKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "* In Python, you typically use Scikit-learn's train_test_split() function to divide your dataset:"
      ],
      "metadata": {
        "id": "i880iKMF8sLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "b30HkhRF9Mpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X is the feature matrix\n",
        "\n",
        "y is the target vector\n",
        "\n",
        "test_size=0.2 means 20% of the data is used for testing\n",
        "\n",
        "random_state ensures reproducibility\n",
        "\n",
        "To approach a machine learning problem:\n",
        "\n",
        "Understand the problem and data.\n",
        "\n",
        "Perform exploratory data analysis (EDA).\n",
        "\n",
        "Preprocess: handle missing values, encode categories, scale features.\n",
        "\n",
        "Split data into training and testing sets.\n",
        "\n",
        "Choose and train a model.\n",
        "\n",
        "Evaluate with appropriate metrics.\n",
        "\n",
        "Tune hyperparameters.\n",
        "\n",
        "Deploy and monitor the model."
      ],
      "metadata": {
        "id": "CoqEM30V9QrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "* Exploratory Data Analysis (EDA) is essential before fitting a model because it helps you understand the structure, quality, and patterns in your data. Key reasons to perform EDA include:\n",
        "\n",
        "Identify missing values or incorrect data types\n",
        "\n",
        "Detect outliers or unusual patterns\n",
        "\n",
        "Understand distributions of features\n",
        "\n",
        "Reveal relationships between variables\n",
        "\n",
        "Guide feature selection and engineering\n",
        "\n",
        "Prevent data leakage and bias\n",
        "\n",
        "Ensure the data is suitable for modeling\n",
        "\n",
        "EDA ensures you're building your model on clean, well-understood data, leading to better performance and insights."
      ],
      "metadata": {
        "id": "3GMszUSR9Z6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is correlation?\n",
        "* Correlation is a statistical measure that indicates the strength and direction of a linear relationship between two variables. It ranges from -1 to 1:\n",
        "\n",
        "+1: Perfect positive correlation (as one increases, the other increases)\n",
        "\n",
        "0: No linear correlation\n",
        "\n",
        "–1: Perfect negative correlation (as one increases, the other decreases)\n",
        "\n",
        "For example, height and weight often have a positive correlation, while hours of TV watched and test scores might show a negative correlation.\n",
        "\n",
        "Correlation helps identify dependencies between variables during data analysis."
      ],
      "metadata": {
        "id": "CPzDWJ409iWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What does negative correlation mean?\n",
        "Negative correlation means that as one variable increases, the other decreases — they move in opposite directions. The correlation coefficient for a negative correlation falls between 0 and -1.\n",
        "\n",
        "A value close to -1 indicates a strong negative relationship.\n",
        "\n",
        "A value close to 0 means a weak or no linear relationship.\n",
        "\n",
        "Example: As the number of hours studied decreases, exam scores tend to decrease — this would be a positive correlation.\n",
        "But if the number of hours watching TV increases and exam scores decrease, that’s a negative correlation."
      ],
      "metadata": {
        "id": "PKL_cTGb9pGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How can you find correlation between variables in Python?\n",
        "* Using .corr() in Pandas:"
      ],
      "metadata": {
        "id": "enfSYYDc91ML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'age': [25, 32, 47, 51, 62],\n",
        "    'income': [50000, 60000, 80000, 82000, 90000]\n",
        "})\n",
        "\n",
        "# Compute correlation matrix\n",
        "correlation_matrix = data.corr()\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "id": "A5XtnWM2-FLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "To visualize:"
      ],
      "metadata": {
        "id": "f6d_jpHp-Gzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zLpM60S5-PS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "* Causation means that one variable directly affects another — a change in one variable causes a change in the other.\n",
        "\n",
        "Difference Between Correlation and Causation:\n",
        "Correlation: Two variables move together, but one does not necessarily cause the other to change.\n",
        "\n",
        "Causation: One variable directly influences the other.\n",
        "\n",
        "Example:\n",
        "Correlation: Ice cream sales and drowning incidents both increase in summer. They’re correlated, but eating ice cream doesn't cause drowning.\n",
        "\n",
        "Causation: Smoking causes lung damage. Here, smoking has a direct causal effect."
      ],
      "metadata": {
        "id": "K9lqxAJD-RmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "* An optimizer is an algorithm used in machine learning to adjust model parameters (like weights) to minimize the loss function during training. It guides how the model learns from data.\n",
        "\n",
        "Common types of optimizers:\n",
        "Gradient Descent – Updates weights using the gradient of the loss.\n",
        "Example: Basic linear regression using gradient descent.\n",
        "\n",
        "Stochastic Gradient Descent (SGD) – Updates weights using one data point at a time.\n",
        "Faster, but noisier.\n",
        "\n",
        "Adam (Adaptive Moment Estimation) – Combines momentum and adaptive learning rates.\n",
        "Widely used in deep learning."
      ],
      "metadata": {
        "id": "CVlh16bL-ds3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is sklearn.linear_model ?\n",
        "* sklearn.linear_model is a module in the Scikit-learn library that provides tools to build and train linear models for regression and classification tasks.\n",
        "\n",
        "Common models in sklearn.linear_model:\n",
        "LinearRegression – For predicting continuous values (e.g., house prices).\n",
        "\n",
        "LogisticRegression – For binary or multi-class classification (e.g., spam detection).\n",
        "\n",
        "Ridge and Lasso – Linear models with regularization to prevent overfitting.\n",
        "\n",
        "SGDRegressor and SGDClassifier – Use stochastic gradient descent for large-scale learning.\n",
        "\n",
        "These models are easy to use, fast, and effective for many ML problems."
      ],
      "metadata": {
        "id": "i4feNsNu-m1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What does model.fit() do? What arguments must be given?\n",
        "* The model.fit() function in machine learning is used to train the model on given data. It adjusts the model's internal parameters (like weights) to learn the relationship between features and target values.\n",
        "\n",
        "What it does:\n",
        "Takes input features (X) and target values (y)\n",
        "\n",
        "Learns from the data by minimizing the loss function\n",
        "\n",
        "Prepares the model to make accurate predictions\n",
        "\n",
        "Required arguments:"
      ],
      "metadata": {
        "id": "3FbQY_rS-zMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y)\n"
      ],
      "metadata": {
        "id": "A3mMdCfW_GKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X: Feature matrix (input data)\n",
        "\n",
        "y: Target values (labels for supervised learning)"
      ],
      "metadata": {
        "id": "aaadxdk1_IHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What does model.predict() do? What arguments must be given?\n",
        "* The model.predict() function is used to make predictions using a trained machine learning model. After training with model.fit(), you use model.predict() to apply the learned patterns to new or test data.\n",
        "\n",
        "What it does:\n",
        "Accepts input features (X)\n",
        "\n",
        "Returns predicted output values (e.g., class labels or numerical predictions)\n",
        "\n",
        "Required argument:"
      ],
      "metadata": {
        "id": "MNFyqFHf_KS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_new)\n"
      ],
      "metadata": {
        "id": "CBKBORBy_eQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X_new: A 2D array or DataFrame of new input data (same number of features as used in training)\n",
        "\n",
        "It helps evaluate model performance or make real-world predictions."
      ],
      "metadata": {
        "id": "h_b1WcqI_foe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What are continuous and categorical variables?\n",
        "* Continuous variables are numerical values that can take any value within a range and are measurable. They often include decimals and can be infinitely divided.\n",
        "Examples: height, temperature, age, income.\n",
        "\n",
        "Categorical variables represent distinct categories or groups and are usually non-numeric, or treated as labels. They can be:\n",
        "\n",
        "Nominal (no natural order): color, gender, country\n",
        "\n",
        "Ordinal (ordered categories): education level, customer rating\n",
        "\n",
        "These variable types are handled differently in data preprocessing — continuous variables are often scaled, while categorical variables are encoded."
      ],
      "metadata": {
        "id": "HYhzK1KL_h6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "* Feature scaling is a preprocessing technique in machine learning where numerical features are rescaled to a common range (e.g., 0–1 or with zero mean and unit variance). This ensures that all features contribute equally to the model.\n",
        "\n",
        "Why it helps:\n",
        "Prevents features with larger ranges from dominating the learning process\n",
        "\n",
        "Speeds up convergence in optimization algorithms (e.g., gradient descent)\n",
        "\n",
        "Improves performance of models sensitive to feature scales (like KNN, SVM, Logistic Regression)\n",
        "\n",
        "Common methods:\n",
        "Normalization (Min-Max Scaling)\n",
        "\n",
        "Standardization (Z-score Scaling)"
      ],
      "metadata": {
        "id": "ckyol2Pk_1in"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. How do we perform scaling in Python?\n",
        "* 1. Standardization (Z-score scaling)\n",
        "Centers data around mean = 0 and standard deviation = 1"
      ],
      "metadata": {
        "id": "sUtbQI-c_9SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "KA_nM3GnAJD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. Normalization (Min-Max scaling)\n",
        "Scales data to a 0–1 range"
      ],
      "metadata": {
        "id": "4sQkXMpuAKWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "ou9-a6C1ANzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace X with your feature data (usually a NumPy array or DataFrame)."
      ],
      "metadata": {
        "id": "c3BNrTfrAPTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is sklearn.preprocessing?\n",
        "* **`sklearn.preprocessing`** is a module in the **Scikit-learn** library used to **prepare and transform data** before training machine learning models. It offers tools for **scaling features**, **encoding categorical variables**, **handling missing values**, and **normalizing data**. This ensures that input data is in a suitable format and scale for algorithms to learn effectively. Common classes include `StandardScaler`, `MinMaxScaler`, `OneHotEncoder`, and `SimpleImputer`. Proper preprocessing improves model performance, convergence speed, and accuracy by treating data inconsistencies and formatting issues.\n"
      ],
      "metadata": {
        "id": "PpJ1x6OHARPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "* To split data for model fitting in Python, you use the train_test_split() function from Scikit-learn. This separates your dataset into training and testing sets."
      ],
      "metadata": {
        "id": "3McmB6YDAhlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "0nk0xr1RAsE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X: Feature variables\n",
        "\n",
        "y: Target variable\n",
        "\n",
        "test_size: Proportion of data used for testing (e.g., 0.2 = 20%)\n",
        "\n",
        "random_state: Ensures reproducibility\n",
        "\n",
        "This helps evaluate how well the model generalizes to new data."
      ],
      "metadata": {
        "id": "hzNhU9IaAtF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.Explain data encoding?\n",
        "* Data encoding is the process of converting categorical (non-numeric) data into a numerical format so that machine learning algorithms can interpret and use it effectively. Since most models work with numbers, encoding is essential for handling variables like gender, color, or product category.\n",
        "\n",
        "Common Encoding Techniques:\n",
        "Label Encoding: Assigns a unique integer to each category (e.g., Red = 0, Blue = 1).\n",
        "\n",
        "One-Hot Encoding: Creates binary columns for each category (e.g., [1, 0, 0] for Red).\n",
        "\n",
        "Proper encoding ensures the model correctly understands the data's structure."
      ],
      "metadata": {
        "id": "786e7A6cAvUX"
      }
    }
  ]
}